{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation\n",
    "## Writeup\n",
    "In this project, a fully convolutional networks is used to label the pixels of a road in images.\n",
    "\n",
    "### Dataset\n",
    "Download the [Kitti Road dataset](http://www.cvlibs.net/datasets/kitti/eval_road.php) from [here](http://www.cvlibs.net/download.php?file=data_road.zip).  Extract the dataset in the `data` folder.  This will create the folder `data_road` with all the training a test images.\n",
    "\n",
    "The Kitti Road dataset contains 289 training images and annotated ground truth images for the road area / pixels. A test set of 290 images is given as well.\n",
    "Current benchmark top entries achieve a Fmax score of > 96%. [Leaderboard] (http://www.cvlibs.net/datasets/kitti/eval_road.php)\n",
    "\n",
    "### FCN Network\n",
    "\n",
    "A Fully Convolutional Network (FCN) is trained to label each pixel into 2 classes (binary) - this can be done by the following three approaches:\n",
    "\n",
    "* 1x1 convolutions\n",
    "* Skip layers to concatenate low level and high level features / convolutions\n",
    "* Upsampling oder Deconvolution using transposed convolution to restore the original input image size\n",
    "\n",
    "A pretrained VGG16 network is used as the encoder, where all fully connected layers are removed and upsampling and skip connections are added.\n",
    "\n",
    "    def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights\n",
    "    vgg_tag = 'vgg16'\n",
    "    \n",
    "    tf_graph = tf.get_default_graph()\n",
    "    \n",
    "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "    \n",
    "    # print names of elements in graph\n",
    "    #for element in tf_graph.get_operations():\n",
    "    #    print(element.name)\n",
    "        \n",
    "    # define names\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    # load VGG pretrained graphs by name\n",
    "    tf_input = tf_graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    tf_prob = tf_graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    tf_layer3 = tf_graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    tf_layer4 = tf_graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    tf_layer7 = tf_graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return tf_input, tf_prob, tf_layer3, tf_layer4, tf_layer7\n",
    "\n",
    "The network is defined in:\n",
    "\n",
    "    def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    \n",
    "    # create the network\n",
    "    # use layers conv2d 1x1 kernel, conv2d_transpose, skip connections\n",
    "    \n",
    "    # encoder is vgg network\n",
    "\n",
    "    # 1x1 convolutions for skip connections\n",
    "    conv1x1_layer7 = tf.layers.conv2d(vgg_layer7_out, num_classes, 1, strides = (1,1), padding='same') \n",
    "    conv1x1_layer4 = tf.layers.conv2d(vgg_layer4_out, num_classes, 1, strides = (1,1), padding='same')\n",
    "    conv1x1_layer3 = tf.layers.conv2d(vgg_layer3_out, num_classes, 1, strides = (1,1), padding='same')\n",
    "    \n",
    "    # conv2transpose deconvolutions to scale up and concatenation with skip connections\n",
    "    # after each upscaling, do conv2d but without changing dimensions\n",
    "    # upscaling is mirrored conv2d downsampling path (number of convolutions and resolutions)\n",
    "    \n",
    "    # first upscaling layer\n",
    "    deconv_layer7 = tf.layers.conv2d_transpose(conv1x1_layer7, num_classes,  4, strides=(2, 2), padding='same')\n",
    "    skip_layer7 = tf.add(deconv_layer7, conv1x1_layer4)\n",
    "    \n",
    "    # second upscaling layer\n",
    "    deconv_layer4 = tf.layers.conv2d_transpose(skip_layer7, num_classes,  4, strides=(2, 2), padding='same')\n",
    "    skip_layer4 = tf.add(deconv_layer4, conv1x1_layer3)\n",
    "    \n",
    "    output = tf.layers.conv2d_transpose(skip_layer4, num_classes,  16, strides=(8, 8), padding='same')\n",
    "\n",
    "    return output\n",
    "\n",
    "### Optimizer and loss function\n",
    "\n",
    "As the optimizer, ADAM is used with a learning rate of 1e-4. The loss is calculated using cross-entropy with logits for 2 classes.\n",
    "\n",
    "    def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    \n",
    "    # define optimizer for training\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    labels = tf.reshape(correct_label, (-1, num_classes))\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy_loss)\n",
    "    \n",
    "    return logits, train_op, cross_entropy_loss\n",
    "    \n",
    "### Training\n",
    "\n",
    "Training is done for 50 epochs, a resolution of 576, 160 px  learning rate of 1e-4 and at a batch size of 2 (TITAN X GPU with 12GB RAM used) in:\n",
    "\n",
    "    def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    \n",
    "    # run training for defined number of epochs with defined parameters\n",
    "    for epoch in range(epochs):\n",
    "        for curr_batch, (curr_image, curr_label) in enumerate(get_batches_fn(batch_size)):\n",
    "            history, curr_loss = sess.run([train_op, cross_entropy_loss],\n",
    "                                          feed_dict = {input_image: curr_image, \n",
    "                                                       correct_label: curr_label, \n",
    "                                                       keep_prob: 0.5, \n",
    "                                                       learning_rate: 1e-4})\n",
    "            print(\"curr batch\", curr_batch, \"curr epoch \", epoch, \"/\", epochs, \"curr loss \", curr_loss)\n",
    "    \n",
    "    pass\n",
    "\n",
    "### Results\n",
    "\n",
    "The training loss is decreasing continously to a value of approx. 0.02.\n",
    "The resulting road segmentation is showing excellent results, labelling a majority > 90% of road pixels correct and less than 10% of non road pixels incorrect.\n",
    "\n",
    "Anyway, this is still far away from the current state of the art benchmark. \n",
    "\n",
    "Here are some test images:\n",
    "\n",
    "![um_000000.png](./runs/1503571676.450356/um_000006.png \"um_000006.png\")\n",
    "![um_000000.png](./runs/1503571676.450356/um_000008.png \"um_000008.png\")\n",
    "![um_000000.png](./runs/1503571676.450356/um_000032.png \"um_000032.png\")\n",
    "![um_000000.png](./runs/1503571676.450356/um_000038.png \"um_000038.png\")\n",
    "![um_000000.png](./runs/1503571676.450356/um_000060.png \"um_000060.png\")\n",
    "![um_000000.png](./runs/1503571676.450356/um_000077.png \"um_000077.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:DeepLearning]",
   "language": "python",
   "name": "conda-env-DeepLearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
